{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from project_paths import paths \n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "from lane_detection_medium.inference import DetectionInference\n",
    "from lane_detection_medium.utils.fs import read_image, read_yolo_labels\n",
    "from lane_detection_medium.utils.viz import render_bbox\n",
    "from lane_detection_medium.types.detection_types import ImageDetections\n",
    "from lane_detection_medium.utils.video_processing import VideoReader\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained Models Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"train-2023-07-05\"\n",
    "\n",
    "CHECKPOINT_DPATH = paths.yolo_dpath / \"LaneMarkingsDetection\" / EXP_NAME / \"weights\"\n",
    "MODEL_FPATH = CHECKPOINT_DPATH / \"best.pt\"\n",
    "\n",
    "inference_wobg = DetectionInference.from_file(\n",
    "    str(MODEL_FPATH), \n",
    "    device=\"cuda:0\", \n",
    "    img_size=(640, 640)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"train-2023-07-10\"\n",
    "\n",
    "CHECKPOINT_DPATH = paths.yolo_dpath / \"LaneMarkingsDetection\" / EXP_NAME / \"weights\"\n",
    "MODEL_FPATH = CHECKPOINT_DPATH / \"best.pt\"\n",
    "\n",
    "inference_wbg = DetectionInference.from_file(\n",
    "    str(MODEL_FPATH), \n",
    "    device=\"cuda:0\", \n",
    "    img_size=(640, 640)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dpath = paths.yolo_dpath / \"data\" / \"2023_07_10\" / \"test\"\n",
    "img_dpath = data_dpath / \"images\"\n",
    "lbl_dpath = data_dpath / \"labels\"\n",
    "\n",
    "img_fpaths = sorted(list((data_dpath / \"images\").glob(\"*.PNG\")))\n",
    "txt_fpaths = sorted(list((data_dpath / \"labels\").glob(\"*.txt\")))\n",
    "\n",
    "len(img_fpaths), len(txt_fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = { \n",
    "  \"solid_white\": (255, 0, 0), \n",
    "  \"break_white\": (0, 0, 255), \n",
    "  \"zebra\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "@interact \n",
    "def show_inference(index=IntSlider(val=0, min=0, max=len(txt_fpaths) - 1)):\n",
    "    txt_fpath = txt_fpaths[index]\n",
    "    img_fpath = img_dpath / f\"{txt_fpath.stem}.PNG\"\n",
    "\n",
    "    test_image = read_image(str(img_fpath))\n",
    "    gt_canva = test_image.copy()\n",
    "    wobg_canva = test_image.copy() \n",
    "    wbg_canva = test_image.copy()\n",
    "\n",
    "    gt_np = read_yolo_labels(txt_fpath)\n",
    "    gt_dets = ImageDetections.from_yolo_labels(gt_np, *test_image.shape[:2])\n",
    "\n",
    "    wobg_detections = inference_wobg.detect([test_image], conf=0.25)[0]\n",
    "    wbg_detections = inference_wbg.detect([test_image], conf=0.25)[0]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15, 25))\n",
    "\n",
    "    # --- Ground Truth Rendering --- #\n",
    "    for gt_det in gt_dets:\n",
    "        label_name = inference_wobg.names_map[gt_det.label_id]\n",
    "        render_bbox(\n",
    "            gt_canva, \n",
    "            gt_det.bbox, \n",
    "            label=label_name, \n",
    "            color=color_map[label_name], \n",
    "            font_color=(255, 255, 255),\n",
    "            line_thickness=4, \n",
    "            font_size=1.5\n",
    "        )\n",
    "    ax[0].imshow(gt_canva)\n",
    "    ax[0].set_title(\"Ground Truth\")\n",
    "\n",
    "    # --- Inference w/o background frames --- # \n",
    "    for det in wobg_detections:\n",
    "        label_name = f\"{det.label_name}: {det.conf:.2f}\"\n",
    "        render_bbox(\n",
    "            wobg_canva, det.bbox, label=label_name, color=color_map[det.label_name], font_color=(255, 255, 255), \n",
    "            line_thickness=4, \n",
    "            font_size=1.5\n",
    "        )\n",
    "    ax[1].imshow(wobg_canva)\n",
    "    ax[1].set_title(\"Inference w/o background\")\n",
    "\n",
    "    # --- Inference w/ background frames --- # \n",
    "    for det in wbg_detections:\n",
    "        label_name = f\"{det.label_name}: {det.conf:.2f}\"\n",
    "        render_bbox(\n",
    "            wbg_canva, det.bbox, label=label_name, color=color_map[det.label_name], font_color=(255, 255, 255), \n",
    "            line_thickness=4, \n",
    "            font_size=1.5\n",
    "        )\n",
    "    ax[2].imshow(wbg_canva)\n",
    "    ax[2].set_title(\"Inference w/ background\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fname = \"no_lines.mp4\"\n",
    "video_fpath = paths.data / \"videos\" / video_fname\n",
    "\n",
    "with VideoReader(video_fpath, verbose=True) as reader: \n",
    "    frames = list(reader.get_frames()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = { \n",
    "  \"solid_white\": (255, 0, 0), \n",
    "  \"break_white\": (0, 0, 255), \n",
    "  \"zebra\": (255, 255, 0)\n",
    "}\n",
    "\n",
    "@interact \n",
    "def show_inference(index=IntSlider(val=0, min=0, max=len(frames) - 1)):\n",
    "    test_image = frames[index]\n",
    "    wobg_canva = test_image.copy() \n",
    "    wbg_canva = test_image.copy()\n",
    "\n",
    "    wobg_detections = inference_wobg.detect([test_image], conf=0.25)[0]\n",
    "    wbg_detections = inference_wbg.detect([test_image], conf=0.25)[0]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 18))\n",
    "\n",
    "\n",
    "    # --- Inference w/o background frames --- # \n",
    "    for det in wobg_detections:\n",
    "        label_name = f\"{det.label_name}: {det.conf:.2f}\"\n",
    "        render_bbox(\n",
    "            wobg_canva, det.bbox, label=label_name, color=color_map[det.label_name], font_color=(255, 255, 255), line_thickness=4, \n",
    "            font_size=1.5\n",
    "        )\n",
    "    ax[0].imshow(wobg_canva)\n",
    "    ax[0].set_title(\"Inference w/o background\")\n",
    "\n",
    "    # --- Inference w/ background frames --- # \n",
    "    for det in wbg_detections:\n",
    "        label_name = f\"{det.label_name}: {det.conf:.2f}\"\n",
    "        render_bbox(\n",
    "            wbg_canva, det.bbox, label=label_name, color=color_map[det.label_name], font_color=(255, 255, 255), line_thickness=4, \n",
    "            font_size=1.5\n",
    "        )\n",
    "    ax[1].imshow(wbg_canva)\n",
    "    ax[1].set_title(\"Inference w/ background\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
